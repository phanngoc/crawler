{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import e\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import os\n",
    "\n",
    "DRIVER_PATH = '/Users/ngocp/.pyenv/versions/3.10.3/lib/python3.10/site-packages/selenium/webdriver'\n",
    "\n",
    "def create_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--window-size=1920,1200\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "driver = create_driver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class CSVWriter:\n",
    "    def __init__(self, csv_file_path, fieldnames):\n",
    "        self.csv_file_path = csv_file_path\n",
    "        self.fieldnames = fieldnames\n",
    "\n",
    "        # Write headers if the file doesn't exist\n",
    "        file_exists = False\n",
    "        try:\n",
    "            with open(csv_file_path, mode='x'):\n",
    "                pass\n",
    "        except FileExistsError:\n",
    "            file_exists = True\n",
    "\n",
    "        if not file_exists:\n",
    "            with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "                writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "\n",
    "    def push_item(self, data_dict):\n",
    "        with open(self.csv_file_path, mode='a', newline='') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=self.fieldnames)\n",
    "            writer.writerow(data_dict)\n",
    "\n",
    "    def truncate_file(self):\n",
    "        try:\n",
    "            with open(self.csv_file_path, mode='w', newline='') as csv_file:\n",
    "                csv_file.write('')\n",
    "            print(f\"CSV file '{self.csv_file_path}' has been truncated.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error truncating CSV file '{self.csv_file_path}': {e}\")\n",
    "\n",
    "\n",
    "fieldnames = [\"title\", \"url\", \"content\", \"date\", \"tags\"]\n",
    "csv_file_path = \"data.csv\"\n",
    "\n",
    "csv_writer = CSVWriter(csv_file_path, fieldnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'backup_title_url.csv' has been truncated.\n",
      "headings_a:len 10\n",
      "heading_elem <selenium.webdriver.remote.webelement.WebElement (session=\"ce159b197a529202f1a44086eb52e4ee\", element=\"4E7295D024EEDFFE5E146C8A99FFCD66_element_132\")>\n",
      "Title: Giao dịch quỹ đầu tư: Lực bán áp đảo\n",
      "Link: https://vietstock.vn/2023/08/giao-dich-quy-dau-tu-luc-ban-ap-dao-3358-1102520.htm\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from time import sleep\n",
    "from regex import F\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import dateparser\n",
    "import crawl\n",
    "reload(crawl)\n",
    "import pandas as pd\n",
    "\n",
    "class Crawl:\n",
    "    csv_writer = None\n",
    "    def __init__(self, csv_backup = {'file_path': None}) -> None:\n",
    "        self.csv_writer = CSVWriter(csv_backup['file_path'], fieldnames=[\"title\", \"url\"])\n",
    "        pass\n",
    "\n",
    "class CrawlVietStock(Crawl):\n",
    "    limit_page = 20\n",
    "    driver = None\n",
    "    links = []\n",
    "    titles = []\n",
    "    retry_backup = False\n",
    "    source = \"https://vietstock.vn/chung-khoan.htm\"\n",
    "    base_url = \"https://vietstock.vn\"\n",
    "\n",
    "    def __init__(self, driver, limit_page = 20) -> None:\n",
    "        self.driver = driver\n",
    "        self.limit_page = limit_page\n",
    "        self.csv_writer = CSVWriter('backup_title_url.csv', fieldnames=[\"title\", \"url\"])\n",
    "        pass\n",
    "\n",
    "    def exist_record(self, url):\n",
    "        query = crawl.CrawlData.select().where(crawl.CrawlData.url == url)\n",
    "        return len(query) > 0\n",
    "\n",
    "    \"\"\"\n",
    "    daily: True if you want to crawl only page not exist in database\n",
    "    retry_backup: True if you want to retry from backup file (link, title)\n",
    "    fresh_start: True if you want to truncate backup file and start from beginning\n",
    "    \"\"\"\n",
    "    def run(self, range_date = {'start_date': None, 'end_date': None},\n",
    "            daily = False, retry_backup = False,\n",
    "            fresh_start = True):\n",
    "        page = 1\n",
    "        self.retry_backup = retry_backup\n",
    "        self.driver.get(self.source)\n",
    "        if fresh_start:\n",
    "            self.csv_writer.truncate_file()\n",
    "\n",
    "        if retry_backup:\n",
    "            url_backup = pd.read_csv('backup_title_url.csv')\n",
    "            self.links = url_backup['url'].tolist()\n",
    "            self.titles = url_backup['title'].tolist()\n",
    "            print('self.links ', self.links[:20], self.titles[:20])\n",
    "            self.get_page_detail()\n",
    "            return\n",
    "\n",
    "        if range_date['start_date'] is not None and daily is not True:\n",
    "            dateRangeElem = driver.find_element(By.CSS_SELECTOR, 'input[name=\"daterange\"]')\n",
    "            dateRangeElem.clear()\n",
    "            dateRangeElem.send_keys(range_date['start_date'] + ' - ' + range_date['end_date'])\n",
    "            dateRangeElem.click()\n",
    "            driver.execute_script(\"$('.AddStockCode').remove();\")\n",
    "            driver.execute_script(\"$('div.trending-fixed').remove();\")\n",
    "            driver.find_element(By.CSS_SELECTOR, '.range_inputs .applyBtn').click()\n",
    "\n",
    "        while True:\n",
    "            headings_a = driver.find_elements(By.CSS_SELECTOR, \"#channel-container .single_post_text h4 a\")\n",
    "            print('headings_a:len', len(headings_a))\n",
    "            if len(headings_a) == 0:\n",
    "                break\n",
    "\n",
    "            for heading_elem in headings_a:\n",
    "                try:\n",
    "                    print('heading_elem', heading_elem)\n",
    "                    title = heading_elem.text\n",
    "                    link_detail = heading_elem.get_attribute(\"href\")\n",
    "                    print(\"Title:\", title)\n",
    "                    print(\"Link:\", link_detail)\n",
    "                    self.csv_writer.push_item({\n",
    "                        'title': title,\n",
    "                        'url': link_detail\n",
    "                    })\n",
    "                    if daily and self.exist_record(link_detail):\n",
    "                        self.get_page_detail()\n",
    "                        return\n",
    "                    self.links.append(link_detail)\n",
    "                    self.titles.append(title)\n",
    "                except Exception as e:\n",
    "                    print('run:e:', e)\n",
    "                    continue\n",
    "\n",
    "            # turn off popup trending\n",
    "            btnTrending = driver.find_elements(By.CSS_SELECTOR, '#button-trending')\n",
    "            if btnTrending:\n",
    "                btnTrending[0].click()\n",
    "\n",
    "            driver.execute_script(\"$('div.trending-fixed').remove();\")\n",
    "\n",
    "            pageCSSSelector = '#content-paging .next'\n",
    "            pageNext = driver.find_elements(By.CSS_SELECTOR, pageCSSSelector)\n",
    "            if len(pageNext) != 0:\n",
    "                pageNext[0].click()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "            sleep(3)\n",
    "            if self.limit_page != -1 and page == self.limit_page:\n",
    "                break\n",
    "            page += 1\n",
    "\n",
    "    def get_page_detail(self):\n",
    "        for key, link_detail in enumerate(self.links):\n",
    "            try:\n",
    "                print('get_page_detail', key, link_detail)\n",
    "                driver.get(link_detail)\n",
    "                contentElem = driver.find_element(By.CSS_SELECTOR, '.single_post_heading')\n",
    "                content = contentElem.text\n",
    "                dateElem = driver.find_element(By.CSS_SELECTOR, '.blog-single-head .date')\n",
    "\n",
    "                datePublish = None\n",
    "                if dateElem:\n",
    "                    date = dateElem.text\n",
    "                    datePublish = dateparser.parse(date)\n",
    "                \n",
    "                crawl.create_article({\n",
    "                    'domain': 'https://vietstock.vn/chung-khoan.htm',\n",
    "                    'title': self.titles[key],\n",
    "                    'url': link_detail,\n",
    "                    'date': datePublish,\n",
    "                    'content': content,\n",
    "                }, True)\n",
    "            except Exception as e:\n",
    "                print('get_page_detail:e:', e)\n",
    "                continue\n",
    "\n",
    "\n",
    "CrawlVietStock(driver, limit_page=-1).run(range_date={'start_date': '2023-05-01', 'end_date': '2023-05-31'},\n",
    "    retry_backup=False, fresh_start=True, daily=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
